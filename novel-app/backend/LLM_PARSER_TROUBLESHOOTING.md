# LLM Parser Troubleshooting Guide

## Issue: Parser Still Using Old Regex Parser

If you upload a new novel but it's still using the old regex parser instead of LLM structure detection, check the following:

## Checklist / Danh sÃ¡ch Kiá»ƒm tra

### 1. **Frontend is Sending LLM Options** / Frontend Äang Gá»­i TÃ¹y chá»n LLM

âœ… **Fixed**: The frontend now sends `useLLMStructureDetection` and `language` in FormData.

**Check:**
- Open browser DevTools â†’ Network tab
- Upload a novel
- Check the request payload
- Should see: `useLLMStructureDetection: "true"` and `language: "auto"`

### 2. **Backend is Receiving Options** / Backend Äang Nháº­n TÃ¹y chá»n

âœ… **Fixed**: Added logging to show received options.

**Check logs:**
```bash
# Look for these log messages:
[Novels Route] ğŸ“¤ Upload request - useLLM: true, language: auto
[Novels Route] ğŸ“¤ Request body keys: novel, useLLMStructureDetection, language
```

### 3. **Ollama is Running** / Ollama Äang Cháº¡y

**Check:**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Should return list of available models
```

**If not running:**
```bash
# Start Ollama (if installed)
ollama serve

# Or check if it's running on different port
# Check OLLAMA_BASE_URL environment variable
```

### 4. **Ollama Model is Available** / Model Ollama CÃ³ sáºµn

**Check:**
```bash
# List available models
ollama list

# Should see: qwen3:8b (or your configured model)
```

**If model not available:**
```bash
# Pull the model
ollama pull qwen3:8b
```

### 5. **Check Backend Logs** / Kiá»ƒm tra Log Backend

Look for these log messages in `novel-app/backend/logs/backend_output.log`:

**âœ… LLM is being used:**
```
[NovelParser] Using LLM structure detection...
[NovelParser] âœ… LLM structure detection service is available
[NovelParser] âœ… LLM detected X structure markers
```

**âŒ LLM is not available (fallback to regex):**
```
[NovelParser] âš ï¸ LLM structure detection not available (Ollama not running or model not available)
[NovelParser] âš ï¸ Falling back to regex-based parsing
```

**âŒ LLM returned no markers (fallback to regex):**
```
[NovelParser] âš ï¸ No structure markers detected by LLM, falling back to regex parser
```

## Common Issues / CÃ¡c Váº¥n Ä‘á» ThÆ°á»ng gáº·p

### Issue 1: Ollama Not Running
**Symptoms:**
- Logs show: "LLM structure detection not available"
- Falls back to regex parser

**Solution:**
1. Start Ollama: `ollama serve`
2. Verify it's running: `curl http://localhost:11434/api/tags`
3. Restart the backend

### Issue 2: Model Not Available
**Symptoms:**
- Logs show: "LLM structure detection not available"
- Ollama is running but model not found

**Solution:**
1. Pull the model: `ollama pull qwen3:8b`
2. Verify: `ollama list`
3. Restart the backend

### Issue 3: LLM Returns No Markers
**Symptoms:**
- Logs show: "LLM detected 0 structure markers"
- Falls back to regex parser

**Possible Causes:**
- Novel has no clear structure markers
- LLM prompt needs adjustment
- Novel format is unusual

**Solution:**
- Check the novel file format
- Try with a different novel that has clear chapter markers
- Check LLM response in logs

### Issue 4: Frontend Not Sending Options
**Symptoms:**
- Backend logs show: `useLLM: false` or missing options

**Solution:**
- âœ… **Fixed**: Frontend now sends options by default
- Clear browser cache and reload
- Check browser DevTools Network tab

## Debugging Steps / CÃ¡c BÆ°á»›c Gá»¡ lá»—i

### Step 1: Check Backend Logs
```bash
# Watch backend logs in real-time
tail -f novel-app/backend/logs/backend_output.log

# Or check recent logs
tail -n 100 novel-app/backend/logs/backend_output.log | grep -i "llm\|parser\|structure"
```

### Step 2: Test Ollama Directly
```bash
# Test Ollama API
curl http://localhost:11434/api/tags

# Test with a simple prompt
curl http://localhost:11434/api/generate -d '{
  "model": "qwen3:8b",
  "prompt": "Hello",
  "stream": false
}'
```

### Step 3: Test LLM Structure Detection Service
```bash
# Create a test script
cd novel-app/backend
node -e "
import('./src/services/novelStructureDetectionService.js').then(async (module) => {
  const service = module.getNovelStructureDetectionService();
  const available = await service.isAvailable();
  console.log('LLM Available:', available);
  
  if (available) {
    const testContent = 'PROLOGUE\nPrologue text.\n\nChapter 1\nChapter 1 text.';
    const result = await service.detectStructure(testContent, { language: 'en' });
    console.log('Structure Index:', JSON.stringify(result, null, 2));
  }
});
"
```

### Step 4: Check Frontend Request
1. Open browser DevTools (F12)
2. Go to Network tab
3. Upload a novel
4. Find the `/api/novels/upload` request
5. Check:
   - Request payload (FormData)
   - Should include: `useLLMStructureDetection: "true"`, `language: "auto"`

## Expected Behavior / HÃ nh vi Mong Ä‘á»£i

### When LLM is Available / Khi LLM CÃ³ sáºµn

1. **Upload novel** â†’ Frontend sends FormData with `useLLMStructureDetection: "true"`
2. **Backend receives** â†’ Logs show: `useLLM: true, language: auto`
3. **Parser checks** â†’ Logs show: `âœ… LLM structure detection service is available`
4. **LLM analyzes** â†’ Logs show: `âœ… LLM detected X structure markers`
5. **Chapters created** â†’ Logs show: `ğŸ“š Parsed X chapters`

### When LLM is Not Available / Khi LLM KhÃ´ng cÃ³ sáºµn

1. **Upload novel** â†’ Frontend sends FormData with `useLLMStructureDetection: "true"`
2. **Backend receives** â†’ Logs show: `useLLM: true, language: auto`
3. **Parser checks** â†’ Logs show: `âš ï¸ LLM structure detection not available`
4. **Falls back** â†’ Logs show: `âš ï¸ Falling back to regex-based parsing`
5. **Regex parses** â†’ Logs show: `ğŸ“š Parsed X chapters` (using regex)

## Force LLM Usage / Ã‰p Sá»­ dá»¥ng LLM

If you want to force LLM usage (even if it fails), you can:

1. **Check Ollama is running:**
   ```bash
   curl http://localhost:11434/api/tags
   ```

2. **Check model is available:**
   ```bash
   ollama list | grep qwen3:8b
   ```

3. **Restart backend:**
   ```bash
   cd novel-app/backend
   python stop_backend.py
   python start_backend.py
   ```

4. **Upload novel again** - Should now use LLM

## Force Regex Parser / Ã‰p Sá»­ dá»¥ng Regex Parser

If you want to disable LLM and use regex parser:

**Option 1: Frontend (temporary)**
- Modify `novel-app/frontend/src/services/novels.ts`
- Change: `formData.append('useLLMStructureDetection', 'false')`

**Option 2: Backend (permanent)**
- Modify `novel-app/backend/src/routes/novels.js`
- Change: `const useLLM = false;` (hardcode)

## Verification / XÃ¡c minh

After uploading a novel, check the logs:

**âœ… LLM was used:**
```
[NovelParser] Using LLM structure detection...
[NovelParser] âœ… LLM structure detection service is available
[NovelParser] âœ… LLM detected X structure markers
[NovelParser] ğŸ“š Parsed X chapters
```

**âŒ Regex was used:**
```
[NovelParser] âš ï¸ LLM structure detection not available
[NovelParser] âš ï¸ Falling back to regex-based parsing
[NovelParser] ğŸ“š Parsed X chapters
```

---

**Status**: âœ… Frontend and Backend Updated  
**Date**: 2024-12-19

