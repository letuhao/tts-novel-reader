# English TTS Models for Novel/Fiction Reading
# M√¥ h√¨nh TTS ti·∫øng Anh cho ƒë·ªçc ti·ªÉu thuy·∫øt/ti·ªÉu thuy·∫øt

## üéØ Overview / T·ªïng quan

This document provides recommendations for English TTS models that are:
- ‚úÖ Suitable for long-form content (novels, fiction, audiobooks)
- ‚úÖ Self-hostable
- ‚úÖ Optimized for RTX 4090 (CUDA support)
- ‚úÖ High quality, natural-sounding voices

T√†i li·ªáu n√†y cung c·∫•p c√°c ƒë·ªÅ xu·∫•t cho m√¥ h√¨nh TTS ti·∫øng Anh:
- ‚úÖ Ph√π h·ª£p v·ªõi n·ªôi dung d√†i (ti·ªÉu thuy·∫øt, ti·ªÉu thuy·∫øt, s√°ch n√≥i)
- ‚úÖ C√≥ th·ªÉ t·ª± l∆∞u tr·ªØ
- ‚úÖ T·ªëi ∆∞u cho RTX 4090 (h·ªó tr·ª£ CUDA)
- ‚úÖ Ch·∫•t l∆∞·ª£ng cao, gi·ªçng n√≥i t·ª± nhi√™n

---

## üèÜ Top Recommendations / ƒê·ªÅ xu·∫•t H√†ng ƒë·∫ßu

### 1. **XTTS-v2 (Coqui TTS)** ‚≠ê RECOMMENDED

**Why it's great:**
- ‚úÖ **High quality**: Natural, expressive speech
- ‚úÖ **Voice cloning**: Clone any voice with 3-6 seconds of reference audio
- ‚úÖ **Multilingual**: Supports English + 16+ languages
- ‚úÖ **Long-form optimized**: Handles long texts efficiently
- ‚úÖ **GPU optimized**: Excellent CUDA support, works great on RTX 4090
- ‚úÖ **Active development**: Well-maintained by Coqui AI
- ‚úÖ **Community support**: Large community, good documentation

**Technical Details:**
- **Model Size**: ~1.7GB
- **VRAM Usage**: ~4-6GB (perfect for RTX 4090's 24GB)
- **Inference Speed**: ~1-2x real-time on RTX 4090
- **Sample Rate**: 22050 Hz (can be upsampled to 44100 Hz)
- **License**: Apache 2.0 (commercial use allowed)

**GitHub**: https://github.com/coqui-ai/TTS
**Hugging Face**: https://huggingface.co/coqui/XTTS-v2

**Installation:**
```bash
pip install TTS
```

**Quick Start:**
```python
from TTS.api import TTS

# Initialize XTTS-v2
tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2", gpu=True)

# Synthesize with voice cloning
tts.tts_to_file(
    text="Your novel text here...",
    speaker_wav="path/to/reference_voice.wav",
    language="en",
    file_path="output.wav"
)
```

**Pros:**
- Best balance of quality, speed, and features
- Voice cloning is excellent for character voices
- Well-documented and actively maintained
- Easy to integrate into existing backend

**Cons:**
- Requires reference audio for voice cloning (but has default voices too)
- Slightly slower than some alternatives

---

### 2. **StyleTTS2** ‚≠ê HIGH QUALITY

**Why it's great:**
- ‚úÖ **Exceptional quality**: One of the best-sounding TTS models
- ‚úÖ **Natural prosody**: Excellent intonation and rhythm
- ‚úÖ **Voice cloning**: Clone voices with reference audio
- ‚úÖ **GPU optimized**: Works well on RTX 4090
- ‚úÖ **Long-form capable**: Handles long texts

**Technical Details:**
- **Model Size**: ~500MB
- **VRAM Usage**: ~3-5GB
- **Inference Speed**: ~0.5-1x real-time (slower than XTTS)
- **Sample Rate**: 24000 Hz
- **License**: MIT (commercial use allowed)

**GitHub**: https://github.com/yl4579/StyleTTS2

**Pros:**
- Highest quality output
- Very natural-sounding
- Good for audiobook narration

**Cons:**
- Slower inference speed
- Less active community than XTTS
- More complex setup

---

### 3. **Piper TTS** ‚ö° FAST & LIGHTWEIGHT

**Why it's great:**
- ‚úÖ **Very fast**: Real-time synthesis on CPU, even faster on GPU
- ‚úÖ **Lightweight**: Small model size (~50-200MB per voice)
- ‚úÖ **Multiple voices**: 100+ pre-trained English voices
- ‚úÖ **Good quality**: Natural-sounding for its size
- ‚úÖ **Easy integration**: Simple API

**Technical Details:**
- **Model Size**: ~50-200MB per voice
- **VRAM Usage**: ~1-2GB
- **Inference Speed**: ~10-20x real-time on RTX 4090
- **Sample Rate**: 22050 Hz
- **License**: MIT (commercial use allowed)

**GitHub**: https://github.com/rhasspy/piper
**Voice Samples**: https://rhasspy.github.io/piper-samples/

**Pros:**
- Extremely fast
- Low resource usage
- Many voice options
- Easy to use

**Cons:**
- Quality not as high as XTTS or StyleTTS2
- Less expressive than advanced models
- No voice cloning

---

### 4. **Tortoise-TTS** üé≠ EXPRESSIVE

**Why it's great:**
- ‚úÖ **Highly expressive**: Great for character voices
- ‚úÖ **Voice cloning**: Excellent voice cloning capabilities
- ‚úÖ **Emotional control**: Can control emotion and style
- ‚úÖ **High quality**: Very natural output

**Technical Details:**
- **Model Size**: ~2GB
- **VRAM Usage**: ~6-8GB
- **Inference Speed**: ~0.1-0.3x real-time (very slow)
- **Sample Rate**: 22050 Hz
- **License**: Apache 2.0

**GitHub**: https://github.com/neonbjb/tortoise-tts

**Pros:**
- Most expressive output
- Excellent for character voices
- Great voice cloning

**Cons:**
- Very slow (10-30 seconds per sentence)
- High VRAM usage
- Not ideal for long-form content due to speed

---

### 5. **Kitten-TTS-Server** üê± LIGHTWEIGHT SERVER

**Why it's great:**
- ‚úÖ **Ultra-lightweight**: Model under 25MB
- ‚úÖ **Server-ready**: Built as a web server
- ‚úÖ **GPU acceleration**: ONNX runtime with GPU support
- ‚úÖ **Long-form optimized**: Automatic text chunking
- ‚úÖ **Web interface**: Built-in UI

**Technical Details:**
- **Model Size**: ~25MB
- **VRAM Usage**: ~1-2GB
- **Inference Speed**: ~5-10x real-time
- **Sample Rate**: 22050 Hz
- **License**: MIT

**GitHub**: https://github.com/devnen/Kitten-TTS-Server

**Pros:**
- Very lightweight
- Server-ready out of the box
- Good for quick setup

**Cons:**
- Lower quality than XTTS/StyleTTS2
- Limited voice options
- Less flexible than other options

---

## üéØ Recommendation for Your Use Case / ƒê·ªÅ xu·∫•t cho Tr∆∞·ªùng h·ª£p S·ª≠ d·ª•ng

### **Best Overall: XTTS-v2** ‚≠ê

For a novel reader application with RTX 4090, **XTTS-v2** is the best choice because:

1. **Quality**: Excellent natural-sounding speech
2. **Speed**: Fast enough for real-time or near real-time synthesis
3. **Features**: Voice cloning allows different character voices
4. **Integration**: Easy to integrate into your existing TTS backend architecture
5. **Resources**: Perfect fit for RTX 4090 (uses ~4-6GB VRAM, leaving room for other tasks)
6. **Long-form**: Handles long texts efficiently
7. **Community**: Active development and good documentation

### **Alternative: StyleTTS2** (if quality is top priority)

If you prioritize absolute best quality over speed, StyleTTS2 is excellent but slower.

### **Alternative: Piper TTS** (if speed is critical)

If you need maximum speed and can accept slightly lower quality, Piper is great.

---

## üîß Integration Plan / K·∫ø ho·∫°ch T√≠ch h·ª£p

### Step 1: Install XTTS-v2

```bash
# In your Python environment
pip install TTS
```

### Step 2: Create Wrapper (Similar to existing Dia/VieNeu wrappers)

Create `app/tts_backend/models/xtts_english.py`:

```python
"""
XTTS-v2 English TTS Wrapper
"""
from TTS.api import TTS
import torch
import numpy as np
from typing import Optional

class XTTSEnglishWrapper:
    """XTTS-v2 English TTS wrapper"""
    
    def __init__(self, device: str = "cuda"):
        self.device = device if torch.cuda.is_available() else "cpu"
        print(f"Loading XTTS-v2 English model on {self.device}...")
        
        # Initialize XTTS-v2
        self.tts = TTS(
            model_name="tts_models/multilingual/multi-dataset/xtts_v2",
            gpu=(self.device == "cuda")
        )
        
        print("‚úÖ XTTS-v2 English model loaded")
    
    def synthesize(
        self,
        text: str,
        speaker_wav: Optional[str] = None,
        language: str = "en",
        **kwargs
    ) -> np.ndarray:
        """
        Synthesize speech
        
        Args:
            text: Input text
            speaker_wav: Path to reference audio for voice cloning (optional)
            language: Language code (default: "en")
            **kwargs: Additional parameters
            
        Returns:
            Audio array (numpy)
        """
        # Use default voice if no reference provided
        if speaker_wav is None:
            # XTTS has built-in voices, use default
            speaker_wav = None  # Will use default voice
        
        # Synthesize
        wav = self.tts.tts(
            text=text,
            speaker_wav=speaker_wav,
            language=language,
            **kwargs
        )
        
        return np.array(wav)
    
    def get_sample_rate(self) -> int:
        """Get sample rate"""
        return 22050  # XTTS default sample rate
```

### Step 3: Update Service

Add to `app/tts_backend/service.py`:

```python
ModelType = Literal["vieneu-tts", "dia", "xtts-english"]

def get_xtts_english(self):
    """Get or load XTTS English model"""
    if self.xtts_english is None:
        from .models.xtts_english import XTTSEnglishWrapper
        self.xtts_english = XTTSEnglishWrapper(device=self.device)
    return self.xtts_english

def synthesize(self, text: str, model: Optional[ModelType] = None, ...):
    # Add XTTS handling
    elif model == "xtts-english":
        xtts = self.get_xtts_english()
        return xtts.synthesize(text, **kwargs)
```

### Step 4: Update API

Add to `app/tts_backend/api.py`:

```python
model: Optional[Literal["vieneu-tts", "dia", "xtts-english"]] = "xtts-english"
speaker_wav: Optional[str] = None  # Reference audio for voice cloning
language: Optional[str] = "en"  # Language code
```

---

## üìä Comparison Table / B·∫£ng So s√°nh

| Model | Quality | Speed | VRAM | Voice Cloning | Long-form | Setup Difficulty |
|-------|---------|-------|------|---------------|-----------|------------------|
| **XTTS-v2** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 4-6GB | ‚úÖ Yes | ‚úÖ Excellent | ‚≠ê Easy |
| **StyleTTS2** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | 3-5GB | ‚úÖ Yes | ‚úÖ Good | ‚≠ê‚≠ê Medium |
| **Piper TTS** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 1-2GB | ‚ùå No | ‚úÖ Good | ‚≠ê Very Easy |
| **Tortoise-TTS** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê | 6-8GB | ‚úÖ Yes | ‚ö†Ô∏è Slow | ‚≠ê‚≠ê‚≠ê Hard |
| **Kitten-TTS** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | 1-2GB | ‚ùå No | ‚úÖ Good | ‚≠ê Easy |

---

## üöÄ Quick Start Guide / H∆∞·ªõng d·∫´n B·∫Øt ƒë·∫ßu Nhanh

### Option 1: XTTS-v2 (Recommended)

```bash
# 1. Install
pip install TTS

# 2. Test
python -c "from TTS.api import TTS; tts = TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=True); tts.tts_to_file('Hello, this is a test of English TTS.', file_path='test.wav')"
```

### Option 2: Piper TTS (Fast & Simple)

```bash
# 1. Install
pip install piper-tts

# 2. Download voice model
# Visit: https://github.com/rhasspy/piper/releases

# 3. Test
piper --model en_US-lessac-medium --output_file test.wav --text "Hello, this is a test."
```

---

## üìù Notes / Ghi ch√∫

1. **RTX 4090**: All these models will work excellently on your RTX 4090 (24GB VRAM)
2. **Long-form**: XTTS-v2 and Piper handle long texts best
3. **Voice Cloning**: XTTS-v2 and StyleTTS2 support voice cloning for character voices
4. **Integration**: XTTS-v2 integrates easiest with your existing architecture
5. **License**: All recommended models allow commercial use

---

## üîó Resources / T√†i nguy√™n

- **XTTS-v2**: https://github.com/coqui-ai/TTS
- **StyleTTS2**: https://github.com/yl4579/StyleTTS2
- **Piper TTS**: https://github.com/rhasspy/piper
- **Tortoise-TTS**: https://github.com/neonbjb/tortoise-tts
- **Kitten-TTS**: https://github.com/devnen/Kitten-TTS-Server

---

## üí° Next Steps / B∆∞·ªõc Ti·∫øp theo

1. **Test XTTS-v2** locally to verify quality and speed
2. **Create wrapper** following the pattern of existing Dia/VieNeu wrappers
3. **Integrate into backend** by updating service.py and api.py
4. **Add voice cloning** support for character voices in novels
5. **Test with long-form content** to ensure performance

Would you like me to help implement the XTTS-v2 integration into your existing backend?

