# TTS Backend Setup Guide / H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t TTS Backend

## üéØ Overview / T·ªïng quan

This guide will help you set up a unified TTS backend service in `D:\Works\source\novel-reader\app` that supports both:
- **VieNeu-TTS** (24 kHz, CPU-friendly)
- **Dia-Finetuning-Vietnamese** (44.1 kHz, GPU-optimized)

H∆∞·ªõng d·∫´n n√†y s·∫Ω gi√∫p b·∫°n thi·∫øt l·∫≠p d·ªãch v·ª• TTS backend th·ªëng nh·∫•t h·ªó tr·ª£ c·∫£ hai:
- **VieNeu-TTS** (24 kHz, th√¢n thi·ªán CPU)
- **Dia-Finetuning-Vietnamese** (44.1 kHz, t·ªëi ∆∞u GPU)

## ‚ö†Ô∏è Critical: Python Version / Quan tr·ªçng: Phi√™n b·∫£n Python

### Problem / V·∫•n ƒë·ªÅ

- ‚ùå **Python 3.13** has no PyTorch CUDA wheels yet
- ‚ùå This prevents GPU acceleration
- ‚ùå VieNeu-TTS setup failed because of this

### Solution / Gi·∫£i ph√°p

**Install Python 3.11 or 3.12** for full CUDA support  
**C√†i ƒë·∫∑t Python 3.11 ho·∫∑c 3.12** ƒë·ªÉ c√≥ h·ªó tr·ª£ CUDA ƒë·∫ßy ƒë·ªß

## üìã Step-by-Step Setup / C√†i ƒë·∫∑t T·ª´ng B∆∞·ªõc

### Step 1: Install Python 3.11 / B∆∞·ªõc 1: C√†i ƒë·∫∑t Python 3.11

**Option A: Using `py` launcher + winget (EASIEST / D·ªÖ nh·∫•t)** - You already have it!  
**T√πy ch·ªçn A: S·ª≠ d·ª•ng `py` launcher + winget (D·ªÖ nh·∫•t)** - B·∫°n ƒë√£ c√≥ n√≥!

```powershell
# Install Python 3.11 with winget (one command!)
winget install Python.Python.3.11

# Verify
py --list

# Create venv with Python 3.11
py -3.11 -m venv .venv
```

See [SETUP_WITH_PY_LAUNCHER.md](./SETUP_WITH_PY_LAUNCHER.md) or [SETUP_EASIEST.md](./SETUP_EASIEST.md) for details.

**Option B: Using uv** - Modern version manager  
**T√πy ch·ªçn B: S·ª≠ d·ª•ng uv** - Version manager hi·ªán ƒë·∫°i

See [SETUP_WITH_UV.md](./SETUP_WITH_UV.md) or [PYTHON_VERSION_MANAGER_SETUP.md](./PYTHON_VERSION_MANAGER_SETUP.md) for quick setup.

**Option B: Using pyenv-win** - Similar to nvm  
**T√πy ch·ªçn B: S·ª≠ d·ª•ng pyenv-win** - Gi·ªëng nvm

See [SETUP_WITH_PYENV.md](./SETUP_WITH_PYENV.md) for setup guide.

**Option C: Using pyenv-win** - Similar to nvm  
**T√πy ch·ªçn C: S·ª≠ d·ª•ng pyenv-win** - Gi·ªëng nvm

See [SETUP_WITH_PYENV.md](./SETUP_WITH_PYENV.md) for setup guide.

**Option D: Manual Installation / C√†i ƒë·∫∑t Th·ªß c√¥ng**

1. **Download Python 3.11:**
   - Visit: https://www.python.org/downloads/release/python-3119/
   - Download: `python-3.11.9-amd64.exe` (Windows 64-bit)

2. **Install Python 3.11:**
   - Run installer
   - ‚úÖ **IMPORTANT:** Check "Add Python 3.11 to PATH"
   - Click "Install Now"

3. **Verify installation:**
   ```powershell
   py -3.11 --version
   # Expected: Python 3.11.9
   ```

### Step 2: Create Virtual Environment / B∆∞·ªõc 2: T·∫°o M√¥i tr∆∞·ªùng ·∫¢o

```powershell
cd D:\Works\source\novel-reader\app
py -3.11 -m venv .venv
```

### Step 3: Activate Virtual Environment / B∆∞·ªõc 3: K√≠ch ho·∫°t M√¥i tr∆∞·ªùng ·∫¢o

```powershell
.\.venv\Scripts\Activate.ps1
```

### Step 4: Upgrade pip / B∆∞·ªõc 4: N√¢ng c·∫•p pip

```powershell
python -m pip install --upgrade pip
```

### Step 5: Install PyTorch with CUDA / B∆∞·ªõc 5: C√†i ƒë·∫∑t PyTorch v·ªõi CUDA

For RTX 4090 with CUDA 13.0, use CUDA 12.1:

```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

**Verify CUDA support:**
```powershell
python -c "import torch; print('CUDA:', torch.cuda.is_available()); print('GPU:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU')"
```

**Expected output:**
```
CUDA: True
GPU: NVIDIA GeForce RTX 4090
```

### Step 6: Install Dependencies / B∆∞·ªõc 6: C√†i ƒë·∫∑t Ph·ª• thu·ªôc

```powershell
pip install -r requirements.txt
```

### Step 7: Verify Setup / B∆∞·ªõc 7: Ki·ªÉm tra C√†i ƒë·∫∑t

```powershell
python -c "import torch; print('PyTorch:', torch.__version__); print('CUDA:', torch.cuda.is_available()); print('Version:', torch.version.cuda)"
```

## üöÄ Running the Service / Ch·∫°y D·ªãch v·ª•

### Start TTS Backend / Kh·ªüi ƒë·ªông TTS Backend

```powershell
# Activate virtual environment
cd D:\Works\source\novel-reader\app
.\.venv\Scripts\Activate.ps1

# Run server
python main.py
```

### Access API / Truy c·∫≠p API

- **API Docs:** http://127.0.0.1:8000/docs
- **Health Check:** http://127.0.0.1:8000/health
- **TTS Endpoints:** http://127.0.0.1:8000/api/tts/

## üìù API Usage Examples / V√≠ d·ª• S·ª≠ d·ª•ng API

### Synthesize with VieNeu-TTS / T·ªïng h·ª£p v·ªõi VieNeu-TTS

```bash
curl -X POST "http://127.0.0.1:8000/api/tts/synthesize" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Xin ch√†o, ƒë√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ t·ªïng h·ª£p gi·ªçng n√≥i ti·∫øng Vi·ªát.",
    "model": "vieneu-tts",
    "ref_audio_path": "../tts/VieNeu-TTS/sample/id_0001.wav",
    "ref_text": "File reference text here"
  }' \
  --output output.wav
```

### Synthesize with Dia TTS / T·ªïng h·ª£p v·ªõi Dia TTS

```bash
curl -X POST "http://127.0.0.1:8000/api/tts/synthesize" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "[01] Xin ch√†o, ƒë√¢y l√† m·ªôt v√≠ d·ª• v·ªÅ t·ªïng h·ª£p gi·ªçng n√≥i ti·∫øng Vi·ªát.",
    "model": "dia",
    "temperature": 1.3,
    "top_p": 0.95,
    "cfg_scale": 3.0
  }' \
  --output output.wav
```

## ‚úÖ Verification Checklist / Danh s√°ch Ki·ªÉm tra

- [ ] Python 3.11 or 3.12 installed
- [ ] Virtual environment created with Python 3.11/3.12
- [ ] PyTorch with CUDA installed
- [ ] CUDA support verified (torch.cuda.is_available() == True)
- [ ] All dependencies installed
- [ ] TTS backend structure created
- [ ] Service can start successfully

## üîß Troubleshooting / X·ª≠ l√Ω S·ª± c·ªë

### Issue: CUDA not available / V·∫•n ƒë·ªÅ: CUDA kh√¥ng kh·∫£ d·ª•ng

**Solution:**
1. Check Python version: `python --version` (should be 3.11 or 3.12)
2. Reinstall PyTorch with CUDA: `pip install torch --index-url https://download.pytorch.org/whl/cu121`
3. Verify GPU: `nvidia-smi`

### Issue: Import errors / V·∫•n ƒë·ªÅ: L·ªói import

**Solution:**
1. Ensure virtual environment is activated
2. Install all dependencies: `pip install -r requirements.txt`
3. Check Python path includes tts directories

## üìö Next Steps / C√°c B∆∞·ªõc Ti·∫øp theo

1. Test the API endpoints
2. Integrate with your frontend
3. Configure model paths if different
4. Set up production deployment

