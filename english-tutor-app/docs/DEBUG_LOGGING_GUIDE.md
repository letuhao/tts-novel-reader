# Debug Logging Guide

**Date:** 2024-12-21  
**Purpose:** Guide for debugging conversation pipeline performance

## ğŸ” Logging Overview

Comprehensive logging has been added throughout the pipeline to help identify performance bottlenecks.

### Log Levels

- **ğŸš€ [PIPELINE]** - Pipeline processing stages
- **ğŸ“ [PARSER]** - Response parsing and validation
- **ğŸµ [TTS-QUEUE]** - TTS queue management
- **ğŸ¤ [TTS]** - Individual TTS generation
- **ğŸ¤ [TTS-SERVICE]** - TTS service layer
- **ğŸ¤– [OLLAMA]** - Ollama API requests
- **âœ… [CHAT]** - Chat endpoint processing
- **â±ï¸** - Performance timings

---

## ğŸ“Š What Gets Logged

### 1. Ollama Response

**Location:** `routes/ollama.ts`

**Logs:**
- Request start time
- Full Ollama response (debug level)
- Response preview (first 500 chars)
- Response length and timing
- Characters per second

**Example:**
```
ğŸ¤– [OLLAMA] Starting Ollama request
ğŸ“¥ [OLLAMA] Full Ollama response: {...}
âœ… [OLLAMA] Ollama response received (timeMs: 3500, charsPerSecond: 45)
```

### 2. Response Parsing

**Location:** `structuredResponseParser.ts`

**Logs:**
- Raw response preview
- JSON extraction
- JSON parsing (success/failure)
- Structure validation
- Parsed chunks summary
- Fallback activation (if needed)

**Example:**
```
ğŸ” [PARSER] Starting structured response parsing
ğŸ“¥ [PARSER] Response preview (first 300 chars)
ğŸ“¦ [PARSER] Extracted JSON preview
âœ… [PARSER] JSON parsed successfully
âœ… [PARSER] Structure validation passed
ğŸ“¦ [PARSER] Parsed chunks summary
âœ… [PARSER] Structured response parsed successfully
```

### 3. TTS Generation

**Location:** `pipelineService.ts` and `ttsService.ts`

**Logs:**
- TTS request start
- Text preview
- TTS backend request time
- Metadata retrieval time
- Audio size
- Total TTS time
- Characters per second

**Example:**
```
ğŸ¤ [TTS] Starting TTS generation for chunk
ğŸ“¡ [TTS-SERVICE] Sending request to TTS backend...
ğŸ“¥ [TTS-SERVICE] TTS backend response received (timeMs: 2500)
âœ… [TTS] TTS generated successfully (totalTimeMs: 3200, charsPerSecond: 15)
```

### 4. TTS Queue

**Location:** `pipelineService.ts`

**Logs:**
- Queue start
- Chunk processing start
- Slot waiting (when queue full)
- Chunk completion
- Queue statistics

**Example:**
```
ğŸµ [TTS-QUEUE] Starting TTS queue processing
ğŸµ [TTS-QUEUE] Starting TTS for chunk (activeCount: 1)
â³ [TTS-QUEUE] Waiting for TTS slot...
âœ… [TTS-QUEUE] Chunk completed, slot freed
ğŸ [TTS-QUEUE] TTS queue processing complete
```

### 5. Performance Timings

**Location:** `routes/ollama.ts`

**Logs:**
- Breakdown of time spent in each stage
- Percentage of total time
- Total request time

**Example:**
```
â±ï¸ Performance timings:
  - Request Start: 0ms (0.0%)
  - Before Ollama: 2ms (0.1%)
  - After Ollama: 3500ms (70.0%)
  - Before First Chunk: 3502ms (70.0%)
  - After First Chunk: 6800ms (100.0%)
  - TOTAL: 6800ms (100.0%)
```

---

## ğŸ¯ Key Metrics to Watch

### 1. Ollama Response Time
- **Target:** < 5 seconds
- **Log:** `âœ… [OLLAMA] Ollama response received`
- **Check:** `timeMs` and `charsPerSecond`

### 2. TTS Generation Time
- **Target:** < 3 seconds per chunk
- **Log:** `âœ… [TTS] TTS generated successfully`
- **Check:** `totalTimeMs` and `charsPerSecond`

### 3. First Chunk Time
- **Target:** < 8 seconds total
- **Log:** `âœ… [CHAT] First chunk ready`
- **Check:** `totalTimeMs` breakdown

### 4. Queue Processing
- **Target:** Max 2-3 concurrent TTS
- **Log:** `ğŸµ [TTS-QUEUE] Starting TTS for chunk`
- **Check:** `activeCount` should never exceed `maxConcurrent`

---

## ğŸ”§ Enabling Debug Logging

### Environment Variables

```bash
# Set log level to debug
LOG_LEVEL=debug

# Enable verbose logging
VERBOSE_LOGGING=true
```

### In Code

The logger automatically uses `debug` level in development mode.

---

## ğŸ“ˆ Performance Analysis

### Example Log Analysis

```
ğŸ¤– [OLLAMA] Starting Ollama request
âœ… [OLLAMA] Ollama response received (timeMs: 3500)  â† Ollama took 3.5s
ğŸš€ [FIRST-CHUNK] Starting first chunk processing
âœ… [PARSER] Structured response parsed successfully (chunkCount: 3)  â† 3 chunks
ğŸ¤ [TTS] Starting TTS generation for chunk
âœ… [TTS] TTS generated successfully (totalTimeMs: 2800)  â† TTS took 2.8s
âœ… [CHAT] First chunk ready (totalTimeMs: 6300)  â† Total: 6.3s
```

**Analysis:**
- Ollama: 3.5s (55% of total)
- TTS: 2.8s (44% of total)
- Parsing: < 0.1s (negligible)
- **Total: 6.3s** âœ… Good!

### Bottleneck Identification

1. **If Ollama > 5s:** Ollama is slow (model/GPU issue)
2. **If TTS > 3s per chunk:** TTS backend is slow
3. **If queue waiting:** Too many concurrent requests
4. **If parsing fails:** Ollama not returning JSON correctly

---

## ğŸ› Common Issues

### Issue 1: Only 1 Chunk Returned

**Symptoms:**
- Response shows only first chunk
- No remaining chunks processed

**Debug:**
- Check `ğŸ“¥ [OLLAMA] Full Ollama response` log
- Verify Ollama returned multiple chunks in JSON
- Check `ğŸ“¦ [PARSER] Parsed chunks summary`

**Solution:**
- Verify Ollama is returning structured JSON
- Check if parsing is failing (fallback activated)

### Issue 2: Slow TTS Generation

**Symptoms:**
- TTS takes > 5 seconds per chunk
- Low `charsPerSecond` value

**Debug:**
- Check `ğŸ¤ [TTS-SERVICE]` logs
- Look for `apiRequestTimeMs` (TTS backend time)
- Check `metadataTimeMs` (metadata retrieval time)

**Solution:**
- TTS backend may be overloaded
- Check TTS backend logs
- Consider reducing `maxConcurrent`

### Issue 3: Queue Blocking

**Symptoms:**
- Many "Waiting for TTS slot" messages
- Chunks processed sequentially instead of parallel

**Debug:**
- Check `ğŸµ [TTS-QUEUE]` logs
- Look for `activeCount` values
- Check if chunks are completing slowly

**Solution:**
- Increase `maxConcurrent` (if TTS backend can handle it)
- Or reduce chunk count (better chunking strategy)

---

## ğŸ“ Log Format

### Structured Logs

All logs use structured format:
```json
{
  "level": "INFO",
  "time": "2024-12-21T14:30:00.000Z",
  "service": "conversation-pipeline",
  "chunkIndex": 0,
  "textLength": 50,
  "timeMs": 2500,
  "msg": "âœ… [TTS] TTS generated successfully"
}
```

### Pretty Logs (Development)

In development, logs are pretty-printed:
```
[14:30:00.000] INFO (conversation-pipeline): âœ… [TTS] TTS generated successfully
  chunkIndex: 0
  textLength: 50
  timeMs: 2500
```

---

## ğŸ¯ Quick Debug Checklist

1. âœ… Check Ollama response time
2. âœ… Verify structured JSON parsing
3. âœ… Check chunk count
4. âœ… Monitor TTS generation times
5. âœ… Verify queue concurrency
6. âœ… Check for errors/warnings
7. âœ… Review performance timings

---

## ğŸ“Š Performance Targets

| Stage | Target | Warning | Critical |
|-------|--------|---------|----------|
| Ollama Response | < 5s | 5-8s | > 8s |
| TTS Generation | < 3s/chunk | 3-5s | > 5s |
| First Chunk Total | < 8s | 8-12s | > 12s |
| Queue Concurrency | 2-3 | 1 or 4+ | 0 or 5+ |

---

**Status:** âœ… Debug logging implemented and ready

